{
  "header": {
    "github": "GitHub",
    "download": "Download Free"
  },
  "hero": {
    "title": "The prompt",
    "titleHighlight": "engineering platform.",
    "subtitle": "Build, test, compare, and evaluate AI prompts at scale. Create agents, run multi-provider comparisons, grade outputs automatically. Transform prompt craft into prompt engineering.",
    "downloadButton": "Download Free for macOS",
    "githubButton": "View on GitHub",
    "screenshotAlt": "Incito desktop application showing prompt editor with variables, agents, and run mode"
  },
  "problem": {
    "heading": "Prompts deserve better tooling.",
    "items": [
      {
        "title": "Prompts are engineering, not guesswork",
        "description": "You iterate on prompts but have no way to measure improvement. Did that tweak help? Which version performs better? Without evaluation, optimization is blind."
      },
      {
        "title": "One provider isn't enough",
        "description": "GPT-4, Claude, Gemini—each has strengths. But testing the same prompt across providers means copy-pasting and comparing manually. Time-consuming and error-prone."
      },
      {
        "title": "Prompts need version control and structure",
        "description": "High-value prompt logic buried in chat histories and scattered notes. No way to track changes, no way to collaborate, no way to build systematic improvements."
      }
    ]
  },
  "howItWorks": {
    "heading": "How it works",
    "steps": [
      {
        "step": "1",
        "title": "Engineer your templates",
        "description": "Create prompts with variables, conditionals, and structured inputs. Define text fields, dropdowns, sliders, images—whatever your workflow needs."
      },
      {
        "step": "2",
        "title": "Run and compare",
        "description": "Execute prompts in guided run mode. Test across multiple providers simultaneously. See outputs side-by-side with token counts and timing."
      },
      {
        "step": "3",
        "title": "Grade and evaluate",
        "description": "Set up automated graders—assertions for deterministic checks, LLM judges for nuanced evaluation. Know instantly if outputs meet your standards."
      },
      {
        "step": "4",
        "title": "Iterate with confidence",
        "description": "Track run history, compare versions, measure improvements. Build prompts that get better over time, not just different."
      }
    ]
  },
  "features": {
    "heading": "Core features",
    "items": [
      {
        "title": "Local-first. Zero telemetry.",
        "description": "Your prompts never leave your device until you choose. No accounts required. No cloud sync. Enterprise-ready privacy by default."
      },
      {
        "title": "Markdown-native",
        "description": "Plain markdown files with YAML frontmatter. Sync with git, share via Dropbox, version control everything. Your prompts are portable and yours."
      },
      {
        "title": "9 variable types",
        "description": "Text, textarea, number, slider, select, multi-select, array, image, and datetime. Build sophisticated input forms for any use case."
      },
      {
        "title": "Conditional logic",
        "description": "Use {{variables}}, {{#if}} blocks, and helpers. Your prompts become programmable templates that handle edge cases elegantly."
      },
      {
        "title": "AI-assisted editing",
        "description": "Generate prompts from descriptions, refine with instructions, auto-fill variables from context. Your AI provider, your choice."
      },
      {
        "title": "Version history",
        "description": "Every save creates a version. Compare changes, restore previous versions, never lose good work. Built-in undo for your prompt engineering."
      }
    ]
  },
  "experiments": {
    "heading": "Experimental features",
    "subheading": "Pushing the boundaries of prompt engineering. These features are in active development—enable them in settings to try them out.",
    "items": [
      {
        "title": "AI Agents",
        "description": "Create conversational AI assistants with custom system prompts and behavior. Chat directly with your prompts, iterate through conversation.",
        "benefit": "Turn static prompts into interactive workflows"
      },
      {
        "title": "Run Mode",
        "description": "Step-through guided execution with live preview. Fill variables interactively, see your prompt assemble in real-time, execute with one click.",
        "benefit": "Guided prompt execution for teams"
      },
      {
        "title": "Multi-Provider Comparison",
        "description": "Test the same prompt across OpenAI, Anthropic, and Google simultaneously. Compare outputs side-by-side with token counts and costs.",
        "benefit": "Find the best model for each prompt"
      },
      {
        "title": "Graders",
        "description": "Automated evaluation with assertions (contains, regex, length checks) and LLM judges (quality scoring with custom criteria).",
        "benefit": "Measure prompt quality automatically"
      },
      {
        "title": "Playbooks",
        "description": "Create teaching rules to guide AI behavior. Define triggers, instructions, and golden examples. Build consistent AI responses across your team.",
        "benefit": "Teach AI how to respond correctly"
      },
      {
        "title": "Batch Runs",
        "description": "Execute prompts across multiple input variations simultaneously. Test edge cases, compare outputs in a grid, identify variance across scenarios.",
        "benefit": "Test at scale in one click"
      },
      {
        "title": "Custom Runs",
        "description": "Create runs from scratch or modify existing prompts on the fly. Edit templates, adjust variables, configure providers—all in one flexible workspace.",
        "benefit": "Iterate faster without saving"
      },
      {
        "title": "Resources & RAG",
        "description": "Upload documents and images to your resource library. Semantic search with embeddings. Build context-aware prompts from your knowledge base.",
        "benefit": "Ground prompts in your own data"
      },
      {
        "title": "MCP Integration",
        "description": "Connect to Claude Desktop, Cursor, and Claude Code via Model Context Protocol. Access your prompts from any MCP-compatible tool.",
        "benefit": "Use prompts everywhere you work"
      }
    ]
  },
  "chromeExtension": {
    "heading": "Chrome extension coming",
    "subheading": "Access your prompt library directly in Claude, ChatGPT, and any AI interface. Same precision. Zero context switching.",
    "comingSoon": "Join the waitlist"
  },
  "cta": {
    "heading": "Stop guessing. Start measuring.",
    "subheading": "Transform your best prompts into tested, versioned, evaluated systems. Free, open-source, and entirely yours.",
    "downloadButton": "Download Free for macOS",
    "githubButton": "View on GitHub",
    "freeForever": "Free forever. Open source.",
    "comingSoon": "Windows and Linux coming soon"
  },
  "footer": {
    "builtBy": "Built by",
    "sourceCode": "Source code",
    "openSource": "Open source"
  }
}
